{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f505f1ae-1d3a-4bfa-ab4c-c4e3ad45f16d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T19:44:05.137475Z",
     "iopub.status.busy": "2023-08-25T19:44:05.136677Z",
     "iopub.status.idle": "2023-08-25T19:52:32.474526Z",
     "shell.execute_reply": "2023-08-25T19:52:32.473529Z",
     "shell.execute_reply.started": "2023-08-25T19:44:05.137445Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/Concept_ZSL/src/train/TinyImageNetLoader.py:5: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55c323f3662d414aa6ccd46fe7ba51f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preloading val data...:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da6263e5a8264b2d80d764a03e991066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preloading train data...:   0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from TinyImageNetLoader import TinyImageNetDataset\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2302, 0.2265, 0.2262]),\n",
    "])\n",
    "\n",
    "valset = TinyImageNetDataset(\"/datasets/tiny-imagenet-200\", mode=\"val\", transform=val_transform)\n",
    "#print(next(enumerate(validation_loader)))\n",
    "\n",
    "train_transform =  transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2302, 0.2265, 0.2262]),\n",
    "])\n",
    "\n",
    "trainset = TinyImageNetDataset(\"/datasets/tiny-imagenet-200\", transform=train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b35ba9e-4cfc-44f1-81e3-e3d6989dee3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T20:03:03.769829Z",
     "iopub.status.busy": "2023-08-25T20:03:03.769540Z",
     "iopub.status.idle": "2023-08-25T20:03:03.775007Z",
     "shell.execute_reply": "2023-08-25T20:03:03.773911Z",
     "shell.execute_reply.started": "2023-08-25T20:03:03.769810Z"
    }
   },
   "outputs": [],
   "source": [
    "validation_loader = torch.utils.data.DataLoader(\n",
    "        valset, batch_size=1024, shuffle=False, num_workers=4)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "        trainset, batch_size=1024, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c25e694-a6cd-4f61-b939-596672d57ce1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T20:33:08.741822Z",
     "iopub.status.busy": "2023-08-25T20:33:08.740748Z",
     "iopub.status.idle": "2023-08-25T20:33:08.750804Z",
     "shell.execute_reply": "2023-08-25T20:33:08.750208Z",
     "shell.execute_reply.started": "2023-08-25T20:33:08.741814Z"
    }
   },
   "outputs": [],
   "source": [
    "eps=1e-10\n",
    "import torch.nn as nn\n",
    "def loss_fn(out, labels, predicate_matrix):\n",
    "    out = out.view(-1, 1, NUM_FEATURES) # out is a batch of 1D binary vectors\n",
    "    ANDed = out * predicate_matrix # AND operation\n",
    "    diff = ANDed - out # Difference of ANDed and out => if equal, then out is a subset of its class' predicates\n",
    "\n",
    "    entr_loss = nn.CrossEntropyLoss()\n",
    "    loss_cl = entr_loss(diff.sum(dim=2), labels) # Is \"out\" a subset of its class' predicates?\n",
    "\n",
    "    batch_size = out.shape[0]\n",
    "\n",
    "    classes = torch.zeros(batch_size, NUM_CLASSES, device=\"cuda\")\n",
    "    classes[torch.arange(batch_size), labels] = 1\n",
    "    classes = classes.view(batch_size, NUM_CLASSES, 1).expand(batch_size, NUM_CLASSES, NUM_FEATURES)\n",
    "\n",
    "    extra_features = out - predicate_matrix + (out - predicate_matrix).pow(2)\n",
    "\n",
    "    loss_neg_ft = torch.masked_select(extra_features, (1-classes).bool()).view(-1, NUM_FEATURES).sum() / batch_size\n",
    "\n",
    "    labels_predicate = predicate_matrix[labels]\n",
    "    extra_features_in = torch.masked_select(extra_features, classes.bool()).view(-1, NUM_FEATURES)\n",
    "    loss_pos_ft = (labels_predicate - out.view(batch_size, NUM_FEATURES) + extra_features_in/2).sum() / batch_size\n",
    "    \n",
    "    feature_losses = loss_neg_ft * FT_WEIGHT * loss_cl.item()/(loss_neg_ft.item() + eps) + loss_pos_ft * POS_FT_WEIGHT * loss_cl.item()/(loss_pos_ft.item() + eps)\n",
    "\n",
    "    return loss_cl + feature_losses\n",
    "\n",
    "def train_one_epoch():\n",
    "    running_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data[\"images\"], data[\"labels\"]\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs, commit_loss, predicate_matrix = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels, predicate_matrix) + commit_loss\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    return running_loss / (i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb8256b1-2c31-4f7a-9df7-ed0a32e2c89e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T20:32:17.092716Z",
     "iopub.status.busy": "2023-08-25T20:32:17.092041Z",
     "iopub.status.idle": "2023-08-25T20:32:55.859907Z",
     "shell.execute_reply": "2023-08-25T20:32:55.858293Z",
     "shell.execute_reply.started": "2023-08-25T20:32:17.092680Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/Concept_ZSL/src/models\n",
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:16<08:07, 16.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 5.828151082992553, ACC: 0.004942602012306452, FP: 0.0\n",
      "tensor([[[0.],\n",
      "         [1.]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [00:34<07:57, 17.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 5.828151082992553, ACC: 0.004942602012306452, FP: 0.0\n",
      "tensor([[[0.],\n",
      "         [1.]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [00:38<08:57, 19.18s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(EPOCHS)):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m# Make sure gradient tracking is on, and do a pass over the data\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 39\u001b[0m     avg_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     running_vloss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# Set the model to evaluation mode, disabling dropout and using population\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# statistics for batch normalization.\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [8], line 37\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Here, we use enumerate(training_loader) instead of\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# iter(training_loader) so that we can track the batch\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# index and do some intra-epoch reporting\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(training_loader):\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# Every data instance is an input + label pair\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m], data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     40\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1290\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1294\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1295\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1296\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.9/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/usr/lib/python3.9/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.9/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/usr/lib/python3.9/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/usr/lib/python3.9/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torchmetrics import Accuracy\n",
    "import sys, os\n",
    "sys.path.insert(0, \"/\".join(os.path.abspath('').split(\"/\")[:-1]) + \"/models\")\n",
    "print(\"/\".join(os.path.abspath('').split(\"/\")[:-1]) + \"/models\")\n",
    "from ResnetAutoPredicates import ResExtr\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "NUM_FEATURES = 448\n",
    "NUM_CLASSES = 200\n",
    "EPOCHS = 30\n",
    "accuracy = Accuracy(task=\"multiclass\", num_classes=NUM_CLASSES, top_k=1).to(device)\n",
    "\n",
    "POS_FT_WEIGHT = 0\n",
    "FT_WEIGHT = 0.1\n",
    "\n",
    "model = ResExtr(NUM_FEATURES, NUM_CLASSES, pretrained=True).to(device)\n",
    "\n",
    "model.resnet.fc = nn.Linear(512, NUM_FEATURES).to(device)\n",
    "model.resnet.avgpool = nn.AdaptiveAvgPool2d(1).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-4, weight_decay=1e-5)\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "best_stats = {\n",
    "    \"epoch\": 0,\n",
    "    \"train_loss\": 0,\n",
    "    \"val_loss\": 0,\n",
    "    \"val_acc\": 0,\n",
    "    \"val_fp\": 0,\n",
    "}\n",
    "\n",
    "from tqdm import tqdm\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch()\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "    running_acc = 0.0\n",
    "    running_false_positives = 0.0\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(validation_loader):\n",
    "            vinputs, vlabels = vdata[\"images\"], vdata[\"labels\"]\n",
    "            vinputs = vinputs.to(device)\n",
    "            vlabels = vlabels.to(device)\n",
    "            voutputs, vcommit_loss, predicate_matrix = model(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels, predicate_matrix) + vcommit_loss\n",
    "            running_vloss += vloss.item()\n",
    "            voutputs = voutputs.view(-1, 1, NUM_FEATURES)\n",
    "            ANDed = voutputs * predicate_matrix\n",
    "            diff = ANDed - voutputs\n",
    "            running_acc += accuracy(diff.sum(dim=2), vlabels)\n",
    "            voutputs = voutputs.view(-1, NUM_FEATURES)\n",
    "            running_false_positives += ((predicate_matrix[vlabels] - voutputs) == -1).sum() / voutputs.shape[0]\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    avg_acc = running_acc / (i + 1)\n",
    "    avg_false_positives = running_false_positives / (i + 1)\n",
    "    print(f\"LOSS: {avg_vloss}, ACC: {avg_acc}, FP: {avg_false_positives}\")\n",
    "    print(model.bin_quantize._codebook.embed)\n",
    "\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        best_stats[\"epoch\"] = epoch\n",
    "        best_stats[\"train_loss\"] = avg_loss\n",
    "        best_stats[\"val_loss\"] = avg_vloss\n",
    "        best_stats[\"val_acc\"] = avg_acc.item()\n",
    "        best_stats[\"val_fp\"] = avg_false_positives.item()\n",
    "\n",
    "\n",
    "print(best_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f2878d-7a22-4695-8aac-044edeaffe33",
   "metadata": {},
   "source": [
    "# Resnet Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471e85ff-0482-43b3-a266-d08d47200412",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-25T19:16:32.792951Z",
     "iopub.status.idle": "2023-08-25T19:16:32.793145Z",
     "shell.execute_reply": "2023-08-25T19:16:32.793036Z",
     "shell.execute_reply.started": "2023-08-25T19:16:32.793036Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch_baseline():\n",
    "    running_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data[\"images\"], data[\"labels\"]\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn_baseline(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    return running_loss / (i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ce98db-f75b-49df-8b19-913de05ca871",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-25T19:16:32.796340Z",
     "iopub.status.idle": "2023-08-25T19:16:32.796548Z",
     "shell.execute_reply": "2023-08-25T19:16:32.796475Z",
     "shell.execute_reply.started": "2023-08-25T19:16:32.796474Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "NUM_CLASSES = 200\n",
    "EPOCHS = 30\n",
    "accuracy = Accuracy(task=\"multiclass\", num_classes=NUM_CLASSES, top_k=1).to(device)\n",
    "\n",
    "POS_FT_WEIGHT = 0\n",
    "FT_WEIGHT = 0\n",
    "\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "model.fc = nn.Linear(2048, NUM_CLASSES)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "loss_fn_baseline = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "best_stats = {\n",
    "    \"epoch\": 0,\n",
    "    \"train_loss\": 0,\n",
    "    \"val_loss\": 0,\n",
    "    \"val_acc\": 0,\n",
    "}\n",
    "\n",
    "from tqdm import tqdm\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch_baseline()\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "    running_acc = 0.0\n",
    "    running_false_positives = 0.0\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(validation_loader):\n",
    "            vinputs, vlabels = vdata[\"images\"], vdata[\"labels\"]\n",
    "            vinputs = vinputs.to(device)\n",
    "            vlabels = vlabels.to(device)\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = loss_fn_baseline(voutputs, vlabels)\n",
    "            running_vloss += vloss.item()\n",
    "            running_acc += accuracy(voutputs, vlabels)\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    avg_acc = running_acc / (i + 1)\n",
    "    print(f\"LOSS: {avg_vloss}, ACC: {avg_acc}\")\n",
    "\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        best_stats[\"epoch\"] = epoch\n",
    "        best_stats[\"train_loss\"] = avg_loss\n",
    "        best_stats[\"val_loss\"] = avg_vloss\n",
    "        best_stats[\"val_acc\"] = avg_acc.item()\n",
    "\n",
    "print(best_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
