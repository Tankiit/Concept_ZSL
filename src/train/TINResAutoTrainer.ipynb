{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f505f1ae-1d3a-4bfa-ab4c-c4e3ad45f16d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T12:28:21.771587Z",
     "iopub.status.busy": "2023-10-13T12:28:21.770897Z",
     "iopub.status.idle": "2023-10-13T12:41:10.265013Z",
     "shell.execute_reply": "2023-10-13T12:41:10.264263Z",
     "shell.execute_reply.started": "2023-10-13T12:28:21.771587Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preloading val data...: 100%|██████████| 10000/10000 [01:10<00:00, 142.22it/s]\n",
      "Preloading train data...: 100%|██████████| 100000/100000 [11:33<00:00, 144.25it/s]\n"
     ]
    }
   ],
   "source": [
    "from TinyImageNetLoader import TinyImageNetDataset\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "valset = TinyImageNetDataset(\"/datasets/tiny-imagenet-200\", mode=\"val\", transform=val_transform)\n",
    "#print(next(enumerate(validation_loader)))\n",
    "\n",
    "train_transform =  transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "trainset = TinyImageNetDataset(\"/datasets/tiny-imagenet-200\", transform=train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b35ba9e-4cfc-44f1-81e3-e3d6989dee3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T12:44:28.020831Z",
     "iopub.status.busy": "2023-10-13T12:44:28.020127Z",
     "iopub.status.idle": "2023-10-13T12:44:28.024472Z",
     "shell.execute_reply": "2023-10-13T12:44:28.023744Z",
     "shell.execute_reply.started": "2023-10-13T12:44:28.020799Z"
    }
   },
   "outputs": [],
   "source": [
    "validation_loader = torch.utils.data.DataLoader(\n",
    "        valset, batch_size=256, shuffle=False, num_workers=4)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "        trainset, batch_size=256, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c25e694-a6cd-4f61-b939-596672d57ce1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T12:45:07.140560Z",
     "iopub.status.busy": "2023-10-13T12:45:07.140287Z",
     "iopub.status.idle": "2023-10-13T12:45:07.146621Z",
     "shell.execute_reply": "2023-10-13T12:45:07.145869Z",
     "shell.execute_reply.started": "2023-10-13T12:45:07.140541Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "eps=1e-10\n",
    "def loss_fn(out, labels, predicate_matrix):\n",
    "    out = out.view(-1, 1, NUM_FEATURES) # out is a batch of 1D binary vectors\n",
    "    ANDed = out * predicate_matrix # AND operation\n",
    "    diff = ANDed - out # Difference of ANDed and out => if equal, then out is a subset of its class' predicates\n",
    "\n",
    "    entr_loss = torch.nn.CrossEntropyLoss()\n",
    "    loss_cl = entr_loss(diff.sum(dim=2), labels) # Is \"out\" a subset of its class' predicates?\n",
    "\n",
    "    batch_size = out.shape[0]\n",
    "\n",
    "    out = out.view(-1, NUM_FEATURES)\n",
    "    diff_square = (out - predicate_matrix[labels]).pow(2)\n",
    "    \n",
    "    false_positives = (out - predicate_matrix[labels] + diff_square).sum() / batch_size\n",
    "    missing_attr = (predicate_matrix[labels] - out + diff_square).sum() / batch_size\n",
    "    \n",
    "    loss_ft = (1 + false_positives + missing_attr)\n",
    "    loss_ft *= loss_cl.item()/(loss_ft.item() + eps)\n",
    "    \n",
    "    return loss_cl + loss_ft * FT_WEIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "658cfa75-b121-418d-8bda-32a9a22c3d6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T12:45:27.526972Z",
     "iopub.status.busy": "2023-10-13T12:45:27.526246Z",
     "iopub.status.idle": "2023-10-13T12:45:27.531635Z",
     "shell.execute_reply": "2023-10-13T12:45:27.530712Z",
     "shell.execute_reply.started": "2023-10-13T12:45:27.526948Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(scheduler):\n",
    "    running_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data[\"images\"], data[\"labels\"]\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs, commit_loss, predicate_matrix = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels, predicate_matrix) + commit_loss\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    return running_loss / (i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb8256b1-2c31-4f7a-9df7-ed0a32e2c89e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T13:14:16.403395Z",
     "iopub.status.busy": "2023-10-13T13:14:16.402625Z",
     "iopub.status.idle": "2023-10-13T13:32:34.634580Z",
     "shell.execute_reply": "2023-10-13T13:32:34.634053Z",
     "shell.execute_reply.started": "2023-10-13T13:14:16.403377Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/Concept_ZSL/src/models\n",
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [18:18<00:00, 15.69s/it, LOSS: 5.009602475166321, ACC: 0.4854492247104645, FP: 4.552734375, MA: 3.5965821743011475, OA: 11.45127010345459]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 36, 'train_loss': 2.1793006579284473, 'val_loss': 4.711245334148407, 'val_acc': 0.4901367127895355, 'fp': 4.1708984375, 'ma': 3.57763671875, 'oa': 10.9697265625}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics import Accuracy\n",
    "import sys, os\n",
    "sys.path.insert(0, \"/\".join(os.path.abspath('').split(\"/\")[:-1]) + \"/models\")\n",
    "print(\"/\".join(os.path.abspath('').split(\"/\")[:-1]) + \"/models\")\n",
    "from ResnetAutoPredicates import ResExtr\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "NUM_FEATURES = 64\n",
    "NUM_CLASSES = 200\n",
    "EPOCHS = 70\n",
    "accuracy = Accuracy(task=\"multiclass\", num_classes=NUM_CLASSES, top_k=1).to(device)\n",
    "\n",
    "FT_WEIGHT = 0.7\n",
    "\n",
    "model = ResExtr(NUM_FEATURES, NUM_CLASSES, pretrained=True).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-4, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, 5e-4, epochs=EPOCHS, steps_per_epoch=len(training_loader))\n",
    "\n",
    "best_stats = {\n",
    "    \"epoch\": 0,\n",
    "    \"train_loss\": 0,\n",
    "    \"val_loss\": 0,\n",
    "    \"val_acc\": 0,\n",
    "    \"fp\": 0,\n",
    "    \"ma\": 0,\n",
    "    \"oa\": 0\n",
    "}\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "pbar = tqdm(range(EPOCHS))\n",
    "\n",
    "for epoch in pbar:\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(scheduler)\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "    running_acc = 0.0\n",
    "    running_false_positives = 0.0\n",
    "    running_missing_attr = 0.0\n",
    "    running_out_attributes= 0.0\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(validation_loader):\n",
    "            vinputs, vlabels = vdata[\"images\"], vdata[\"labels\"]\n",
    "            vinputs = vinputs.to(device)\n",
    "            vlabels = vlabels.to(device)\n",
    "            voutputs, vcommit_loss, predicate_matrix = model(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels, predicate_matrix) + vcommit_loss\n",
    "            running_vloss += vloss.item()\n",
    "            voutputs = voutputs.view(-1, 1, NUM_FEATURES)\n",
    "            ANDed = voutputs * predicate_matrix\n",
    "            diff = ANDed - voutputs\n",
    "            running_acc += accuracy(diff.sum(dim=2), vlabels)\n",
    "            voutputs = voutputs.view(-1, NUM_FEATURES)\n",
    "            running_false_positives += ((predicate_matrix[vlabels] - voutputs) == -1).sum() / voutputs.shape[0]\n",
    "            running_missing_attr += ((voutputs - predicate_matrix[vlabels]) == -1).sum() / voutputs.shape[0]\n",
    "            running_out_attributes += voutputs.sum() / voutputs.shape[0]\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    avg_acc = running_acc / (i + 1)\n",
    "    avg_fp = running_false_positives / (i + 1)\n",
    "    avg_ma = running_missing_attr / (i + 1)\n",
    "    avg_oa = running_out_attributes / (i + 1)\n",
    "    pbar.set_postfix_str(f\"LOSS: {avg_vloss}, ACC: {avg_acc}, FP: {avg_fp}, MA: {avg_ma}, OA: {avg_oa}\")\n",
    "    #print(model.bin_quantize._codebook.embed)\n",
    "    \n",
    "    with open(\"TINRes18AutoPredData.csv\", \"a\") as f:\n",
    "        f.write(f\"{epoch}, {avg_loss}, {avg_vloss}, {avg_acc}, {avg_fp}, {avg_ma}, {avg_oa}\\n\")\n",
    "\n",
    "    if best_stats[\"val_acc\"] < avg_acc:\n",
    "        best_stats[\"epoch\"] = epoch\n",
    "        best_stats[\"train_loss\"] = avg_loss\n",
    "        best_stats[\"val_loss\"] = avg_vloss\n",
    "        best_stats[\"val_acc\"] = avg_acc.item()\n",
    "        best_stats[\"fp\"] = avg_fp.item()\n",
    "        best_stats[\"ma\"] = avg_ma.item()\n",
    "        best_stats[\"oa\"] = avg_oa.item()\n",
    "\n",
    "\n",
    "print(best_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f2878d-7a22-4695-8aac-044edeaffe33",
   "metadata": {},
   "source": [
    "# Resnet Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "471e85ff-0482-43b3-a266-d08d47200412",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T20:04:28.947006Z",
     "iopub.status.busy": "2023-09-01T20:04:28.946725Z",
     "iopub.status.idle": "2023-09-01T20:04:28.952213Z",
     "shell.execute_reply": "2023-09-01T20:04:28.951328Z",
     "shell.execute_reply.started": "2023-09-01T20:04:28.946983Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch_baseline():\n",
    "    running_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data[\"images\"], data[\"labels\"]\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn_baseline(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    return running_loss / (i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93ce98db-f75b-49df-8b19-913de05ca871",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T20:31:28.708988Z",
     "iopub.status.busy": "2023-09-01T20:31:28.708703Z",
     "iopub.status.idle": "2023-09-01T20:35:17.872894Z",
     "shell.execute_reply": "2023-09-01T20:35:17.872159Z",
     "shell.execute_reply.started": "2023-09-01T20:31:28.708967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [00:15<03:32, 15.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 2.7538333177566527, ACC: 0.3666932284832001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [00:30<03:16, 15.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 2.268373465538025, ACC: 0.45415934920310974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [00:45<03:02, 15.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 2.1400376319885255, ACC: 0.4812440574169159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [01:01<02:48, 15.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 1.9924053430557251, ACC: 0.5112384557723999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [01:16<02:33, 15.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 1.9608011841773987, ACC: 0.5201749801635742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [01:31<02:18, 15.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 1.9408017992973328, ACC: 0.5298649072647095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [01:47<02:04, 15.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 1.9406044483184814, ACC: 0.5277164578437805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [02:02<01:47, 15.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 1.9414733171463012, ACC: 0.5363759398460388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [02:18<01:32, 15.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 1.9837289929389954, ACC: 0.5289102792739868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [02:33<01:16, 15.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 2.0138878226280212, ACC: 0.5291215181350708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [02:48<01:01, 15.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 2.0528515219688415, ACC: 0.5269291996955872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [03:03<00:45, 15.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 2.074764096736908, ACC: 0.5255321860313416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [03:18<00:30, 15.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 2.1348794221878054, ACC: 0.5197624564170837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [03:33<00:15, 15.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 2.1823304891586304, ACC: 0.523909866809845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [03:48<00:00, 15.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 2.1891473531723022, ACC: 0.528218686580658\n",
      "{'epoch': 7, 'train_loss': 1.1221286131411183, 'val_loss': 1.9414733171463012, 'val_acc': 0.5363759398460388}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics import Accuracy\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "NUM_CLASSES = 200\n",
    "EPOCHS = 15\n",
    "accuracy = Accuracy(task=\"multiclass\", num_classes=NUM_CLASSES, top_k=1).to(device)\n",
    "\n",
    "POS_FT_WEIGHT = 0\n",
    "FT_WEIGHT = 0\n",
    "\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "model.fc = nn.Linear(512, NUM_CLASSES)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "loss_fn_baseline = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-4, weight_decay=1e-5)\n",
    "\n",
    "best_stats = {\n",
    "    \"epoch\": 0,\n",
    "    \"train_loss\": 0,\n",
    "    \"val_loss\": 0,\n",
    "    \"val_acc\": 0,\n",
    "}\n",
    "\n",
    "from tqdm import tqdm\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch_baseline()\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "    running_acc = 0.0\n",
    "    running_false_positives = 0.0\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(validation_loader):\n",
    "            vinputs, vlabels = vdata[\"images\"], vdata[\"labels\"]\n",
    "            vinputs = vinputs.to(device)\n",
    "            vlabels = vlabels.to(device)\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = loss_fn_baseline(voutputs, vlabels)\n",
    "            running_vloss += vloss.item()\n",
    "            running_acc += accuracy(voutputs, vlabels)\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    avg_acc = running_acc / (i + 1)\n",
    "    print(f\"LOSS: {avg_vloss}, ACC: {avg_acc}\")\n",
    "\n",
    "    if best_stats[\"val_acc\"] < avg_acc:\n",
    "        best_stats[\"epoch\"] = epoch\n",
    "        best_stats[\"train_loss\"] = avg_loss\n",
    "        best_stats[\"val_loss\"] = avg_vloss\n",
    "        best_stats[\"val_acc\"] = avg_acc.item()\n",
    "\n",
    "print(best_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae77e16c-351e-4f3c-a917-2865ea53e95b",
   "metadata": {},
   "source": [
    "# Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6d56a69-72e8-4139-9c32-ffbba2cbbc8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T13:34:46.335581Z",
     "iopub.status.busy": "2023-10-13T13:34:46.335270Z",
     "iopub.status.idle": "2023-10-13T13:34:46.349347Z",
     "shell.execute_reply": "2023-10-13T13:34:46.348642Z",
     "shell.execute_reply.started": "2023-10-13T13:34:46.335557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/Concept_ZSL/src/models\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "eps = 1e-10\n",
    "def loss_fn_optuna(out, labels, predicate_matrix, NUM_FEATURES, FT_WEIGHT):\n",
    "    out = out.view(-1, 1, NUM_FEATURES) # out is a batch of 1D binary vectors\n",
    "    ANDed = out * predicate_matrix # AND operation\n",
    "    diff = ANDed - out # Difference of ANDed and out => if equal, then out is a subset of its class' predicates\n",
    "\n",
    "    entr_loss = nn.CrossEntropyLoss()\n",
    "    loss_cl = entr_loss(diff.sum(dim=2), labels) # Is \"out\" a subset of its class' predicates?\n",
    "\n",
    "    batch_size = out.shape[0]\n",
    "\n",
    "    out = out.view(-1, NUM_FEATURES)\n",
    "    diff_square = (out - predicate_matrix[labels]).pow(2)\n",
    "    \n",
    "    false_positives = (out - predicate_matrix[labels] + diff_square).sum() / batch_size\n",
    "    missing_attr = (predicate_matrix[labels] - out + diff_square).sum() / batch_size\n",
    "    \n",
    "    loss_ft = (1 + false_positives + missing_attr)\n",
    "    loss_ft *= loss_cl.item()/(loss_ft.item() + eps)\n",
    "    \n",
    "    return loss_cl + loss_ft * FT_WEIGHT\n",
    "\n",
    "from torchmetrics import Accuracy\n",
    "def train_one_epoch_optuna(model, optimizer, scheduler, NUM_FEATURES, FT_WEIGHT):\n",
    "    running_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data[\"images\"], data[\"labels\"]\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs, commit_loss, predicate_matrix = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn_optuna(outputs, labels, predicate_matrix, NUM_FEATURES, FT_WEIGHT) + commit_loss\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    return running_loss / (i+1)\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "\n",
    "import sys, os\n",
    "sys.path.insert(0, \"/\".join(os.path.abspath('').split(\"/\")[:-1]) + \"/models\")\n",
    "print(\"/\".join(os.path.abspath('').split(\"/\")[:-1]) + \"/models\")\n",
    "from ResnetAutoPredicates import ResExtr\n",
    "\n",
    "def objective(trial):\n",
    "    global trial_num\n",
    "    trial_num += 1\n",
    "    print(f\"Starting trial {trial_num}\")\n",
    "    NUM_FEATURES = trial.suggest_int(\"num_features\", 4, 16)\n",
    "    FT_WEIGHT = trial.suggest_float(\"ft_weight\", 0, 1)\n",
    "    # Generate the model.\n",
    "    model = ResExtr(NUM_FEATURES*8, NUM_CLASSES, pretrained=True).to(device)\n",
    "\n",
    "    EPOCHS = 50\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True)\n",
    "    max_lr = trial.suggest_float(\"max_lr\", 1e-4, 4e-3, log=True)\n",
    "    \n",
    "    if lr > max_lr:\n",
    "        raise optuna.TrialPruned()\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=EPOCHS, steps_per_epoch=len(training_loader))\n",
    "\n",
    "    best_acc = 0.0\n",
    "\n",
    "    pbar = tqdm(range(EPOCHS))\n",
    "    for epoch in pbar:\n",
    "        # Make sure gradient tracking is on, and do a pass over the data\n",
    "        model.train(True)\n",
    "        _ = train_one_epoch_optuna(model, optimizer, scheduler, NUM_FEATURES*8, FT_WEIGHT)\n",
    "\n",
    "        model.eval()\n",
    "        running_acc = 0.0\n",
    "\n",
    "        # Disable gradient computation and reduce memory consumption.\n",
    "        with torch.no_grad():\n",
    "            for i, vdata in enumerate(validation_loader):\n",
    "                vinputs, vlabels = vdata[\"images\"], vdata[\"labels\"]\n",
    "                vinputs = vinputs.to(device)\n",
    "                vlabels = vlabels.to(device)\n",
    "                voutputs, _, predicate_matrix = model(vinputs)\n",
    "                voutputs = voutputs.view(-1, 1, NUM_FEATURES*8)\n",
    "                ANDed = voutputs * predicate_matrix\n",
    "                diff = ANDed - voutputs\n",
    "                running_acc += accuracy(diff.sum(dim=2), vlabels)\n",
    "\n",
    "        avg_acc = running_acc / (i + 1)\n",
    "        pbar.set_postfix_str(f\"ACC: {avg_acc}\")\n",
    "\n",
    "        if avg_acc > best_acc:\n",
    "            best_acc = avg_acc\n",
    "\n",
    "        if epoch == 30 and best_acc < 0.3:\n",
    "            raise optuna.TrialPruned()\n",
    "        elif epoch == 15 and best_acc < 0.1:\n",
    "            raise optuna.TrialPruned()\n",
    "    \n",
    "    return best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39892819-1942-425a-8d2e-d3dc8ceca6a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T13:34:48.173894Z",
     "iopub.status.busy": "2023-10-13T13:34:48.173324Z",
     "iopub.status.idle": "2023-10-13T17:24:34.726477Z",
     "shell.execute_reply": "2023-10-13T17:24:34.725521Z",
     "shell.execute_reply.started": "2023-10-13T13:34:48.173872Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-13 13:34:48,235] Using an existing study with name 'TIN-ResNet18-AutoPred50' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Starting trial 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [12:49<00:00, 15.40s/it, ACC: 0.508593738079071]  \n",
      "[I 2023-10-13 13:47:38,608] Trial 1 finished with value: 0.510546863079071 and parameters: {'num_features': 11, 'ft_weight': 0.21935673023924307, 'lr': 1.7167562294364418e-05, 'max_lr': 0.0011501295319336989}. Best is trial 1 with value: 0.510546863079071.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-13 13:47:39,081] Trial 2 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [12:44<00:00, 15.29s/it, ACC: 0.49853515625]      \n",
      "[I 2023-10-13 14:00:24,311] Trial 3 finished with value: 0.49951171875 and parameters: {'num_features': 14, 'ft_weight': 0.7939863651996772, 'lr': 7.690743109731049e-05, 'max_lr': 0.00013688128691750003}. Best is trial 1 with value: 0.510546863079071.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [12:42<00:00, 15.26s/it, ACC: 0.4931640625]       \n",
      "[I 2023-10-13 14:13:07,857] Trial 4 finished with value: 0.4951171875 and parameters: {'num_features': 14, 'ft_weight': 0.8611505723866981, 'lr': 3.056886218349674e-05, 'max_lr': 0.00046599358804611283}. Best is trial 1 with value: 0.510546863079071.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [12:42<00:00, 15.25s/it, ACC: 0.48320314288139343]\n",
      "[I 2023-10-13 14:25:50,503] Trial 5 finished with value: 0.48613283038139343 and parameters: {'num_features': 6, 'ft_weight': 0.2976142931260036, 'lr': 0.0001119688645396934, 'max_lr': 0.0027770232749718704}. Best is trial 1 with value: 0.510546863079071.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [12:38<00:00, 15.17s/it, ACC: 0.515917956829071]  \n",
      "[I 2023-10-13 14:38:29,860] Trial 6 finished with value: 0.51806640625 and parameters: {'num_features': 7, 'ft_weight': 0.18995618534649383, 'lr': 6.4876288607133e-05, 'max_lr': 0.00037619695818120666}. Best is trial 6 with value: 0.51806640625.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [12:50<00:00, 15.40s/it, ACC: 0.49531251192092896]\n",
      "[I 2023-10-13 14:51:20,719] Trial 7 finished with value: 0.49531251192092896 and parameters: {'num_features': 14, 'ft_weight': 0.5772691618290632, 'lr': 1.1310082967073951e-05, 'max_lr': 0.001050714067671693}. Best is trial 6 with value: 0.51806640625.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [12:46<00:00, 15.34s/it, ACC: 0.50634765625]      \n",
      "[I 2023-10-13 15:04:08,047] Trial 8 finished with value: 0.5088867545127869 and parameters: {'num_features': 13, 'ft_weight': 0.3674204716276448, 'lr': 4.136947072409993e-05, 'max_lr': 0.0007749745820584464}. Best is trial 6 with value: 0.51806640625.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [12:46<00:00, 15.33s/it, ACC: 0.4986328184604645] \n",
      "[I 2023-10-13 15:16:55,224] Trial 9 finished with value: 0.49931642413139343 and parameters: {'num_features': 12, 'ft_weight': 0.7524542413775797, 'lr': 2.2172571202409232e-05, 'max_lr': 0.000570021835799505}. Best is trial 6 with value: 0.51806640625.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-13 15:16:55,723] Trial 10 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [12:47<00:00, 15.35s/it, ACC: 0.512402355670929]  \n",
      "[I 2023-10-13 15:29:43,894] Trial 11 finished with value: 0.5140625238418579 and parameters: {'num_features': 8, 'ft_weight': 0.0044688007772815674, 'lr': 0.0001473944606781968, 'max_lr': 0.0003139445734931126}. Best is trial 6 with value: 0.51806640625.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [12:43<00:00, 15.26s/it, ACC: 0.5106445550918579] \n",
      "[I 2023-10-13 15:42:27,839] Trial 12 finished with value: 0.5106445550918579 and parameters: {'num_features': 8, 'ft_weight': 0.02535873641539843, 'lr': 0.00017378868618930874, 'max_lr': 0.0003016290570968002}. Best is trial 6 with value: 0.51806640625.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [12:37<00:00, 15.14s/it, ACC: 0.51611328125]      \n",
      "[I 2023-10-13 15:55:05,647] Trial 13 finished with value: 0.517285168170929 and parameters: {'num_features': 9, 'ft_weight': 0.0012140908688575364, 'lr': 0.00024550936478905994, 'max_lr': 0.0003108933933457271}. Best is trial 6 with value: 0.51806640625.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-13 15:55:06,089] Trial 14 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [12:45<00:00, 15.32s/it, ACC: 0.513867199420929]  \n",
      "[I 2023-10-13 16:07:52,537] Trial 15 finished with value: 0.517578125 and parameters: {'num_features': 9, 'ft_weight': 0.16430276672639066, 'lr': 5.428315605446366e-05, 'max_lr': 0.00040553819511015583}. Best is trial 6 with value: 0.51806640625.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [12:50<00:00, 15.41s/it, ACC: 0.5140625238418579] \n",
      "[I 2023-10-13 16:20:43,455] Trial 16 finished with value: 0.5140625238418579 and parameters: {'num_features': 16, 'ft_weight': 0.41937230638263145, 'lr': 6.48854361675037e-05, 'max_lr': 0.00047549171165264857}. Best is trial 6 with value: 0.51806640625.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [12:39<00:00, 15.19s/it, ACC: 0.48359376192092896]\n",
      "[I 2023-10-13 16:33:23,420] Trial 17 finished with value: 0.49091798067092896 and parameters: {'num_features': 6, 'ft_weight': 0.19221798736081427, 'lr': 5.064141205111694e-05, 'max_lr': 0.00010024112056060755}. Best is trial 6 with value: 0.51806640625.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [12:37<00:00, 15.15s/it, ACC: 0.5069336295127869] \n",
      "[I 2023-10-13 16:46:01,644] Trial 18 finished with value: 0.509765625 and parameters: {'num_features': 10, 'ft_weight': 0.2814229714259377, 'lr': 7.156104300564866e-05, 'max_lr': 0.00019658724586958486}. Best is trial 6 with value: 0.51806640625.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [12:35<00:00, 15.10s/it, ACC: 0.48515626788139343]\n",
      "[I 2023-10-13 16:58:37,328] Trial 19 finished with value: 0.4864257872104645 and parameters: {'num_features': 4, 'ft_weight': 0.4929967805053706, 'lr': 3.395796582636252e-05, 'max_lr': 0.0007525776321807799}. Best is trial 6 with value: 0.51806640625.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [13:09<00:00, 15.78s/it, ACC: 0.5171875357627869] \n",
      "[I 2023-10-13 17:11:47,060] Trial 20 finished with value: 0.5185546875 and parameters: {'num_features': 8, 'ft_weight': 0.1411101232079125, 'lr': 0.00010794944363649746, 'max_lr': 0.0004323540810907836}. Best is trial 20 with value: 0.5185546875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [12:35<00:00, 15.12s/it, ACC: 0.5166992545127869] \n",
      "[I 2023-10-13 17:24:23,444] Trial 21 finished with value: 0.518261730670929 and parameters: {'num_features': 7, 'ft_weight': 0.10396439217336619, 'lr': 0.00010528689766442166, 'max_lr': 0.0006624848455169455}. Best is trial 20 with value: 0.5185546875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:10<?, ?it/s]\n",
      "[W 2023-10-13 17:24:34,350] Trial 22 failed with parameters: {'num_features': 7, 'ft_weight': 0.1087614224956118, 'lr': 0.00010038223252236046, 'max_lr': 0.0006095011915820249} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_87/1434010226.py\", line 93, in objective\n",
      "    _ = train_one_epoch_optuna(model, optimizer, scheduler, NUM_FEATURES*8, FT_WEIGHT)\n",
      "  File \"/tmp/ipykernel_87/1434010226.py\", line 42, in train_one_epoch_optuna\n",
      "    outputs, commit_loss, predicate_matrix = model(inputs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/notebooks/Concept_ZSL/src/models/ResnetAutoPredicates.py\", line 61, in forward\n",
      "    quantize, _, commit_loss = self.bin_quantize(x)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/vector_quantize_pytorch/vector_quantize_pytorch.py\", line 891, in forward\n",
      "    quantize, embed_ind, distances = self._codebook(x, **codebook_forward_kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/amp/autocast_mode.py\", line 16, in decorate_autocast\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/vector_quantize_pytorch/vector_quantize_pytorch.py\", line 478, in forward\n",
      "    quantize = einsum('h b n c, h c d -> h b n d', unpacked_onehot, embed)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/functional.py\", line 377, in einsum\n",
      "    return _VF.einsum(equation, operands)  # type: ignore[attr-defined]\n",
      "KeyboardInterrupt\n",
      "[W 2023-10-13 17:24:34,359] Trial 22 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m trial_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     11\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m, study_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTIN-ResNet18-AutoPred50\u001b[39m\u001b[38;5;124m'\u001b[39m, load_if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, storage\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msqlite:///Optuna.db\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m trial \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_trial\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/study.py:442\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    341\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn [12], line 93\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# Make sure gradient tracking is on, and do a pass over the data\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 93\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch_optuna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_FEATURES\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFT_WEIGHT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     96\u001b[0m     running_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n",
      "Cell \u001b[0;32mIn [12], line 42\u001b[0m, in \u001b[0;36mtrain_one_epoch_optuna\u001b[0;34m(model, optimizer, scheduler, NUM_FEATURES, FT_WEIGHT)\u001b[0m\n\u001b[1;32m     39\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Make predictions for this batch\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m outputs, commit_loss, predicate_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Compute the loss and its gradients\u001b[39;00m\n\u001b[1;32m     45\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn_optuna(outputs, labels, predicate_matrix, NUM_FEATURES, FT_WEIGHT) \u001b[38;5;241m+\u001b[39m commit_loss\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/notebooks/Concept_ZSL/src/models/ResnetAutoPredicates.py:61\u001b[0m, in \u001b[0;36mResExtr.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     59\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresnet(x)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m     quantize, _, commit_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbin_quantize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     predicate_matrix, _, commit_loss2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbin_quantize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicate_matrix\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     64\u001b[0m     predicate_matrix \u001b[38;5;241m=\u001b[39m predicate_matrix\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/vector_quantize_pytorch/vector_quantize_pytorch.py:891\u001b[0m, in \u001b[0;36mVectorQuantize.forward\u001b[0;34m(self, x, indices, mask, sample_codebook_temp, freeze_codebook)\u001b[0m\n\u001b[1;32m    883\u001b[0m codebook_forward_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    884\u001b[0m     sample_codebook_temp \u001b[38;5;241m=\u001b[39m sample_codebook_temp,\n\u001b[1;32m    885\u001b[0m     mask \u001b[38;5;241m=\u001b[39m mask,\n\u001b[1;32m    886\u001b[0m     freeze_codebook \u001b[38;5;241m=\u001b[39m freeze_codebook\n\u001b[1;32m    887\u001b[0m )\n\u001b[1;32m    889\u001b[0m \u001b[38;5;66;03m# quantize\u001b[39;00m\n\u001b[0;32m--> 891\u001b[0m quantize, embed_ind, distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_codebook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcodebook_forward_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;66;03m# one step in-place update\u001b[39;00m\n\u001b[1;32m    895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_inplace_optimize \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m freeze_codebook:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/amp/autocast_mode.py:16\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/vector_quantize_pytorch/vector_quantize_pytorch.py:478\u001b[0m, in \u001b[0;36mEuclideanCodebook.forward\u001b[0;34m(self, x, sample_codebook_temp, mask, freeze_codebook)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m    477\u001b[0m     unpacked_onehot \u001b[38;5;241m=\u001b[39m unpack_one(embed_onehot, ps, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh * c\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 478\u001b[0m     quantize \u001b[38;5;241m=\u001b[39m \u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mh b n c, h c d -> h b n d\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munpacked_onehot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    480\u001b[0m     quantize \u001b[38;5;241m=\u001b[39m batched_embedding(embed_ind, embed)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/functional.py:377\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, \u001b[38;5;241m*\u001b[39m_operands)\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39menabled:\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[0;32m--> 377\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    379\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39mis_available():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "NUM_CLASSES = 200\n",
    "accuracy = Accuracy(task=\"multiclass\", num_classes=NUM_CLASSES, top_k=1).to(device)\n",
    "\n",
    "trial_num = -1\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", study_name='TIN-ResNet18-AutoPred50', load_if_exists=True, storage='sqlite:///Optuna.db')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    if key == \"num_features\":\n",
    "        print(\"    {}: {}\".format(key, value*8))\n",
    "    else:\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
