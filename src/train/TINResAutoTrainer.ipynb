{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f505f1ae-1d3a-4bfa-ab4c-c4e3ad45f16d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T19:34:31.403201Z",
     "iopub.status.busy": "2023-09-01T19:34:31.402671Z",
     "iopub.status.idle": "2023-09-01T19:44:17.751068Z",
     "shell.execute_reply": "2023-09-01T19:44:17.750464Z",
     "shell.execute_reply.started": "2023-09-01T19:34:31.403179Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/Concept_ZSL/src/train/TinyImageNetLoader.py:5: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "541cf153c1cd44e59070da4d693fbdf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preloading val data...:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e02339bddd1a4b0eb7dfd5d1e750c098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preloading train data...:   0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from TinyImageNetLoader import TinyImageNetDataset\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "normalize = transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2302, 0.2265, 0.2262])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "valset = TinyImageNetDataset(\"/datasets/tiny-imagenet-200\", mode=\"val\", transform=val_transform)\n",
    "#print(next(enumerate(validation_loader)))\n",
    "\n",
    "train_transform =  transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "trainset = TinyImageNetDataset(\"/datasets/tiny-imagenet-200\", transform=train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b35ba9e-4cfc-44f1-81e3-e3d6989dee3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T19:44:20.926532Z",
     "iopub.status.busy": "2023-09-01T19:44:20.925701Z",
     "iopub.status.idle": "2023-09-01T19:44:20.933855Z",
     "shell.execute_reply": "2023-09-01T19:44:20.933143Z",
     "shell.execute_reply.started": "2023-09-01T19:44:20.926532Z"
    }
   },
   "outputs": [],
   "source": [
    "validation_loader = torch.utils.data.DataLoader(\n",
    "        valset, batch_size=1024, shuffle=False, num_workers=4)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "        trainset, batch_size=1024, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c25e694-a6cd-4f61-b939-596672d57ce1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T19:44:25.165552Z",
     "iopub.status.busy": "2023-09-01T19:44:25.164791Z",
     "iopub.status.idle": "2023-09-01T19:44:25.172444Z",
     "shell.execute_reply": "2023-09-01T19:44:25.171815Z",
     "shell.execute_reply.started": "2023-09-01T19:44:25.165531Z"
    }
   },
   "outputs": [],
   "source": [
    "eps=1e-10\n",
    "import torch.nn as nn\n",
    "def loss_fn(out, labels, predicate_matrix):\n",
    "    out = out.view(-1, 1, NUM_FEATURES) # out is a batch of 1D binary vectors\n",
    "    ANDed = out * predicate_matrix # AND operation\n",
    "    diff = ANDed - out # Difference of ANDed and out => if equal, then out is a subset of its class' predicates\n",
    "\n",
    "    entr_loss = nn.CrossEntropyLoss()\n",
    "    loss_cl = entr_loss(diff.sum(dim=2), labels) # Is \"out\" a subset of its class' predicates?\n",
    "\n",
    "    batch_size = out.shape[0]\n",
    "\n",
    "    classes = torch.zeros(batch_size, NUM_CLASSES, device=\"cuda\")\n",
    "    classes[torch.arange(batch_size), labels] = 1\n",
    "    classes = classes.view(batch_size, NUM_CLASSES, 1).expand(batch_size, NUM_CLASSES, NUM_FEATURES)\n",
    "\n",
    "    extra_features = out - predicate_matrix + (out - predicate_matrix).pow(2)\n",
    "\n",
    "    loss_neg_ft = torch.masked_select(extra_features, (1-classes).bool()).view(-1, NUM_FEATURES).sum() / batch_size\n",
    "\n",
    "    labels_predicate = predicate_matrix[labels]\n",
    "    extra_features_in = torch.masked_select(extra_features, classes.bool()).view(-1, NUM_FEATURES)\n",
    "    loss_pos_ft = (labels_predicate - out.view(batch_size, NUM_FEATURES) + extra_features_in/2).sum() / batch_size\n",
    "    \n",
    "    feature_losses = loss_neg_ft * FT_WEIGHT * loss_cl.item()/(loss_neg_ft.item() + eps) + loss_pos_ft * POS_FT_WEIGHT * loss_cl.item()/(loss_pos_ft.item() + eps)\n",
    "\n",
    "    return loss_cl + feature_losses\n",
    "\n",
    "def train_one_epoch():\n",
    "    running_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data[\"images\"], data[\"labels\"]\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs, commit_loss, predicate_matrix = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels, predicate_matrix) + commit_loss\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    return running_loss / (i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb8256b1-2c31-4f7a-9df7-ed0a32e2c89e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T19:55:48.210161Z",
     "iopub.status.busy": "2023-09-01T19:55:48.209487Z",
     "iopub.status.idle": "2023-09-01T20:03:35.155483Z",
     "shell.execute_reply": "2023-09-01T20:03:35.154844Z",
     "shell.execute_reply.started": "2023-09-01T19:55:48.210133Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/Concept_ZSL/src/models\n",
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:15<07:22, 15.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 4.7909797668457035, ACC: 0.21082191169261932, FP: 42.2048225402832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [00:30<07:14, 15.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 4.130327272415161, ACC: 0.3118981122970581, FP: 52.329994201660156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [00:46<06:54, 15.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 3.8393144845962524, ACC: 0.35829681158065796, FP: 56.3805046081543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [01:01<06:37, 15.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 3.7001068353652955, ACC: 0.38954877853393555, FP: 59.440650939941406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [01:16<06:22, 15.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 3.7008814573287965, ACC: 0.4046715795993805, FP: 61.81391525268555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [01:32<06:12, 15.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 3.6758432149887086, ACC: 0.41243621706962585, FP: 63.7144889831543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [01:48<05:57, 15.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 3.6778097629547117, ACC: 0.43310546875, FP: 66.6617202758789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [02:03<05:40, 15.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 3.8360251903533937, ACC: 0.4284937083721161, FP: 70.02547454833984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [02:19<05:26, 15.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 3.788875389099121, ACC: 0.4422851502895355, FP: 70.44908905029297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [02:34<05:11, 15.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 3.915377116203308, ACC: 0.4408721625804901, FP: 71.62947082519531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [02:50<04:55, 15.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 4.000402545928955, ACC: 0.4496830999851227, FP: 73.68814086914062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [03:05<04:38, 15.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 4.025996589660645, ACC: 0.45195111632347107, FP: 75.21492767333984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [03:21<04:23, 15.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 4.091743397712707, ACC: 0.45336219668388367, FP: 76.37532806396484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [03:36<04:08, 15.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 4.217182159423828, ACC: 0.45047831535339355, FP: 78.08949279785156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [03:51<03:51, 15.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 4.279665064811707, ACC: 0.46148356795310974, FP: 79.62401580810547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [04:07<03:36, 15.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 4.398585557937622, ACC: 0.45488080382347107, FP: 81.26549530029297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [04:23<03:22, 15.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 4.451663589477539, ACC: 0.4615214467048645, FP: 82.36861419677734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [04:38<03:06, 15.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 4.501697206497193, ACC: 0.46306800842285156, FP: 84.1758041381836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [04:54<02:52, 15.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 4.556060838699341, ACC: 0.4603196680545807, FP: 85.20101165771484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [05:10<02:36, 15.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 4.616769504547119, ACC: 0.46093350648880005, FP: 85.8296127319336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [05:27<02:24, 16.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 4.790542507171631, ACC: 0.45850205421447754, FP: 87.0041275024414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [05:42<02:05, 15.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 4.765489625930786, ACC: 0.4667111933231354, FP: 87.40892791748047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [05:57<01:48, 15.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 4.78899359703064, ACC: 0.4632274806499481, FP: 89.09098815917969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [06:12<01:32, 15.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 4.926737642288208, ACC: 0.46592196822166443, FP: 89.8622817993164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [06:28<01:17, 15.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 4.998494672775268, ACC: 0.4665597081184387, FP: 90.2645492553711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [06:43<01:02, 15.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 5.008395385742188, ACC: 0.4600406587123871, FP: 91.72443389892578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [06:59<00:46, 15.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 5.115498781204224, ACC: 0.46100130677223206, FP: 91.05828094482422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [07:15<00:31, 15.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 5.126066446304321, ACC: 0.46229472756385803, FP: 92.78614044189453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [07:31<00:15, 15.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 5.183367586135864, ACC: 0.46258172392845154, FP: 92.47284698486328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [07:46<00:00, 15.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 5.274007844924927, ACC: 0.4619559347629547, FP: 93.1252212524414\n",
      "{'epoch': 21, 'train_loss': 1.5405966140785996, 'val_loss': 4.765489625930786, 'val_acc': 0.4667111933231354, 'val_fp': 87.40892791748047}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics import Accuracy\n",
    "import sys, os\n",
    "sys.path.insert(0, \"/\".join(os.path.abspath('').split(\"/\")[:-1]) + \"/models\")\n",
    "print(\"/\".join(os.path.abspath('').split(\"/\")[:-1]) + \"/models\")\n",
    "from ResnetAutoPredicates import ResExtr\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "NUM_FEATURES = 352\n",
    "NUM_CLASSES = 200\n",
    "EPOCHS = 30\n",
    "accuracy = Accuracy(task=\"multiclass\", num_classes=NUM_CLASSES, top_k=1).to(device)\n",
    "\n",
    "POS_FT_WEIGHT = 0\n",
    "FT_WEIGHT = 0\n",
    "\n",
    "model = ResExtr(NUM_FEATURES, NUM_CLASSES, pretrained=True).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-4, weight_decay=1e-5)\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "best_stats = {\n",
    "    \"epoch\": 0,\n",
    "    \"train_loss\": 0,\n",
    "    \"val_loss\": 0,\n",
    "    \"val_acc\": 0,\n",
    "    \"val_fp\": 0,\n",
    "}\n",
    "\n",
    "from tqdm import tqdm\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch()\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "    running_acc = 0.0\n",
    "    running_false_positives = 0.0\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(validation_loader):\n",
    "            vinputs, vlabels = vdata[\"images\"], vdata[\"labels\"]\n",
    "            vinputs = vinputs.to(device)\n",
    "            vlabels = vlabels.to(device)\n",
    "            voutputs, vcommit_loss, predicate_matrix = model(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels, predicate_matrix) + vcommit_loss\n",
    "            running_vloss += vloss.item()\n",
    "            voutputs = voutputs.view(-1, 1, NUM_FEATURES)\n",
    "            ANDed = voutputs * predicate_matrix\n",
    "            diff = ANDed - voutputs\n",
    "            running_acc += accuracy(diff.sum(dim=2), vlabels)\n",
    "            voutputs = voutputs.view(-1, NUM_FEATURES)\n",
    "            running_false_positives += ((predicate_matrix[vlabels] - voutputs) == -1).sum() / voutputs.shape[0]\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    avg_acc = running_acc / (i + 1)\n",
    "    avg_false_positives = running_false_positives / (i + 1)\n",
    "    print(f\"LOSS: {avg_vloss}, ACC: {avg_acc}, FP: {avg_false_positives}\")\n",
    "    #print(model.bin_quantize._codebook.embed)\n",
    "\n",
    "    if best_stats[\"val_acc\"] < avg_acc:\n",
    "        best_vloss = avg_vloss\n",
    "        best_stats[\"epoch\"] = epoch\n",
    "        best_stats[\"train_loss\"] = avg_loss\n",
    "        best_stats[\"val_loss\"] = avg_vloss\n",
    "        best_stats[\"val_acc\"] = avg_acc.item()\n",
    "        best_stats[\"val_fp\"] = avg_false_positives.item()\n",
    "\n",
    "\n",
    "print(best_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f2878d-7a22-4695-8aac-044edeaffe33",
   "metadata": {},
   "source": [
    "# Resnet Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "471e85ff-0482-43b3-a266-d08d47200412",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T20:04:28.947006Z",
     "iopub.status.busy": "2023-09-01T20:04:28.946725Z",
     "iopub.status.idle": "2023-09-01T20:04:28.952213Z",
     "shell.execute_reply": "2023-09-01T20:04:28.951328Z",
     "shell.execute_reply.started": "2023-09-01T20:04:28.946983Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch_baseline():\n",
    "    running_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data[\"images\"], data[\"labels\"]\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn_baseline(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    return running_loss / (i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93ce98db-f75b-49df-8b19-913de05ca871",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T20:31:28.708988Z",
     "iopub.status.busy": "2023-09-01T20:31:28.708703Z",
     "iopub.status.idle": "2023-09-01T20:35:17.872894Z",
     "shell.execute_reply": "2023-09-01T20:35:17.872159Z",
     "shell.execute_reply.started": "2023-09-01T20:31:28.708967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [00:15<03:32, 15.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 2.7538333177566527, ACC: 0.3666932284832001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [00:30<03:16, 15.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 2.268373465538025, ACC: 0.45415934920310974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [00:45<03:02, 15.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 2.1400376319885255, ACC: 0.4812440574169159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [01:01<02:48, 15.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 1.9924053430557251, ACC: 0.5112384557723999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [01:16<02:33, 15.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 1.9608011841773987, ACC: 0.5201749801635742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [01:31<02:18, 15.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 1.9408017992973328, ACC: 0.5298649072647095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [01:47<02:04, 15.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 1.9406044483184814, ACC: 0.5277164578437805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [02:02<01:47, 15.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 1.9414733171463012, ACC: 0.5363759398460388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [02:18<01:32, 15.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 1.9837289929389954, ACC: 0.5289102792739868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [02:33<01:16, 15.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 2.0138878226280212, ACC: 0.5291215181350708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [02:48<01:01, 15.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 2.0528515219688415, ACC: 0.5269291996955872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [03:03<00:45, 15.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 2.074764096736908, ACC: 0.5255321860313416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [03:18<00:30, 15.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 2.1348794221878054, ACC: 0.5197624564170837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [03:33<00:15, 15.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 2.1823304891586304, ACC: 0.523909866809845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [03:48<00:00, 15.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 2.1891473531723022, ACC: 0.528218686580658\n",
      "{'epoch': 7, 'train_loss': 1.1221286131411183, 'val_loss': 1.9414733171463012, 'val_acc': 0.5363759398460388}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics import Accuracy\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "NUM_CLASSES = 200\n",
    "EPOCHS = 15\n",
    "accuracy = Accuracy(task=\"multiclass\", num_classes=NUM_CLASSES, top_k=1).to(device)\n",
    "\n",
    "POS_FT_WEIGHT = 0\n",
    "FT_WEIGHT = 0\n",
    "\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "model.fc = nn.Linear(512, NUM_CLASSES)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "loss_fn_baseline = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-4, weight_decay=1e-5)\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "best_stats = {\n",
    "    \"epoch\": 0,\n",
    "    \"train_loss\": 0,\n",
    "    \"val_loss\": 0,\n",
    "    \"val_acc\": 0,\n",
    "}\n",
    "\n",
    "from tqdm import tqdm\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch_baseline()\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "    running_acc = 0.0\n",
    "    running_false_positives = 0.0\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(validation_loader):\n",
    "            vinputs, vlabels = vdata[\"images\"], vdata[\"labels\"]\n",
    "            vinputs = vinputs.to(device)\n",
    "            vlabels = vlabels.to(device)\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = loss_fn_baseline(voutputs, vlabels)\n",
    "            running_vloss += vloss.item()\n",
    "            running_acc += accuracy(voutputs, vlabels)\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    avg_acc = running_acc / (i + 1)\n",
    "    print(f\"LOSS: {avg_vloss}, ACC: {avg_acc}\")\n",
    "\n",
    "    if best_stats[\"val_acc\"] < avg_acc:\n",
    "        best_vloss = avg_vloss\n",
    "        best_stats[\"epoch\"] = epoch\n",
    "        best_stats[\"train_loss\"] = avg_loss\n",
    "        best_stats[\"val_loss\"] = avg_vloss\n",
    "        best_stats[\"val_acc\"] = avg_acc.item()\n",
    "\n",
    "print(best_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae77e16c-351e-4f3c-a917-2865ea53e95b",
   "metadata": {},
   "source": [
    "# Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6d56a69-72e8-4139-9c32-ffbba2cbbc8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T20:39:02.752279Z",
     "iopub.status.busy": "2023-09-01T20:39:02.751555Z",
     "iopub.status.idle": "2023-09-01T20:39:02.762666Z",
     "shell.execute_reply": "2023-09-01T20:39:02.762248Z",
     "shell.execute_reply.started": "2023-09-01T20:39:02.752221Z"
    }
   },
   "outputs": [],
   "source": [
    "eps = 1e-10\n",
    "def loss_fn_optuna(out, labels, predicate_matrix, NUM_FEATURES, FT_WEIGHT, POS_FT_WEIGHT):\n",
    "        out = out.view(-1, 1, NUM_FEATURES) # out is a batch of 1D binary vectors\n",
    "        ANDed = out * predicate_matrix # AND operation\n",
    "        diff = ANDed - out # Difference of ANDed and out => if equal, then out is a subset of its class' predicates\n",
    "\n",
    "        entr_loss = nn.CrossEntropyLoss()\n",
    "        loss_cl = entr_loss(diff.sum(dim=2), labels) # Is \"out\" a subset of its class' predicates?\n",
    "\n",
    "        batch_size = out.shape[0]\n",
    "\n",
    "        classes = torch.zeros(batch_size, NUM_CLASSES, device=\"cuda\")\n",
    "        classes[torch.arange(batch_size), labels] = 1\n",
    "        classes = classes.view(batch_size, NUM_CLASSES, 1).expand(batch_size, NUM_CLASSES, NUM_FEATURES)\n",
    "\n",
    "        extra_features = out - predicate_matrix + (out - predicate_matrix).pow(2)\n",
    "\n",
    "        loss_neg_ft = torch.masked_select(extra_features, (1-classes).bool()).view(-1, NUM_FEATURES).sum() / batch_size\n",
    "\n",
    "        labels_predicate = predicate_matrix[labels]\n",
    "        extra_features_in = torch.masked_select(extra_features, classes.bool()).view(-1, NUM_FEATURES)\n",
    "        loss_pos_ft = (labels_predicate - out.view(batch_size, NUM_FEATURES) + extra_features_in/2).sum() / batch_size\n",
    "\n",
    "        return loss_cl + loss_neg_ft * FT_WEIGHT * loss_cl.item()/(loss_neg_ft.item() + eps) + loss_pos_ft * POS_FT_WEIGHT * loss_cl.item()/(loss_pos_ft.item() + eps)\n",
    "\n",
    "def train_one_epoch_optuna(model, optimizer, NUM_FEATURES, FT_WEIGHT, POS_FT_WEIGHT):\n",
    "    running_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data[\"images\"], data[\"labels\"]\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs, commit_loss, predicate_matrix = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn_optuna(outputs, labels, predicate_matrix, NUM_FEATURES, FT_WEIGHT, POS_FT_WEIGHT) + commit_loss\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    return running_loss / (i+1)\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "def objective(trial):\n",
    "    global trial_num\n",
    "    trial_num += 1\n",
    "    print(f\"Starting trial {trial_num}\")\n",
    "    NUM_FEATURES = trial.suggest_int(\"num_features\", 0, 12)\n",
    "    FT_WEIGHT = trial.suggest_float(\"ft_weight\", 0, 1.5)\n",
    "    POS_FT_WEIGHT = trial.suggest_float(\"ft_pos_weight\", 0, 1.5)\n",
    "    # Generate the model.\n",
    "    model = ResExtr(256+NUM_FEATURES*16, NUM_CLASSES, pretrained=True).to(device)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    EPOCHS = 30\n",
    "\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in tqdm(range(EPOCHS)):\n",
    "        # Make sure gradient tracking is on, and do a pass over the data\n",
    "        model.train(True)\n",
    "        _ = train_one_epoch_optuna(model, optimizer, 256+NUM_FEATURES*16, FT_WEIGHT, POS_FT_WEIGHT)\n",
    "\n",
    "        model.eval()\n",
    "        running_acc = 0.0\n",
    "\n",
    "        # Disable gradient computation and reduce memory consumption.\n",
    "        with torch.no_grad():\n",
    "            for i, vdata in enumerate(validation_loader):\n",
    "                vinputs, vlabels = vdata[\"images\"], vdata[\"labels\"]\n",
    "                vinputs = vinputs.to(device)\n",
    "                vlabels = vlabels.to(device)\n",
    "                voutputs, _, predicate_matrix = model(vinputs)\n",
    "                voutputs = voutputs.view(-1, 1, 256+NUM_FEATURES*16)\n",
    "                ANDed = voutputs * predicate_matrix\n",
    "                diff = ANDed - voutputs\n",
    "                running_acc += accuracy(diff.sum(dim=2), vlabels)\n",
    "\n",
    "        avg_acc = running_acc / (i + 1)\n",
    "\n",
    "        if avg_acc > best_acc:\n",
    "            best_acc = avg_acc\n",
    "\n",
    "        if epoch == 1 and best_acc < 0.1:\n",
    "            raise optuna.TrialPruned()\n",
    "        elif epoch == 4 and best_acc < 0.3:\n",
    "            raise optuna.TrialPruned()\n",
    "    \n",
    "    return best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39892819-1942-425a-8d2e-d3dc8ceca6a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T20:39:07.441636Z",
     "iopub.status.busy": "2023-09-01T20:39:07.440998Z",
     "iopub.status.idle": "2023-09-01T21:29:19.709575Z",
     "shell.execute_reply": "2023-09-01T21:29:19.708676Z",
     "shell.execute_reply.started": "2023-09-01T20:39:07.441610Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-01 20:39:07,461] A new study created in memory with name: no-name-e69b5ece-29ae-4674-9f35-ca2216a41575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:09, 29.28s/it]\n",
      "[I 2023-09-01 20:39:36,953] Trial 0 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:09, 29.30s/it]\n",
      "[I 2023-09-01 20:40:06,425] Trial 1 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:19, 29.64s/it]\n",
      "[I 2023-09-01 20:40:36,242] Trial 2 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:17, 29.56s/it]\n",
      "[I 2023-09-01 20:41:06,028] Trial 3 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:12, 29.39s/it]\n",
      "[I 2023-09-01 20:41:35,601] Trial 4 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:23, 29.77s/it]\n",
      "[I 2023-09-01 20:42:05,630] Trial 5 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:16, 29.55s/it]\n",
      "[I 2023-09-01 20:42:35,517] Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:18, 29.62s/it]\n",
      "[I 2023-09-01 20:43:05,320] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:06, 29.19s/it]\n",
      "[I 2023-09-01 20:43:34,693] Trial 8 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:13, 29.44s/it]\n",
      "[I 2023-09-01 20:44:04,367] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:16, 29.53s/it]\n",
      "[I 2023-09-01 20:44:34,099] Trial 10 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:13, 29.42s/it]\n",
      "[I 2023-09-01 20:45:03,715] Trial 11 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:23, 29.79s/it]\n",
      "[I 2023-09-01 20:45:33,787] Trial 12 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:13, 29.41s/it]\n",
      "[I 2023-09-01 20:46:03,417] Trial 13 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:04, 29.11s/it]\n",
      "[I 2023-09-01 20:46:32,763] Trial 14 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:16, 29.53s/it]\n",
      "[I 2023-09-01 20:47:02,490] Trial 15 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:30<14:40, 30.37s/it]\n",
      "[I 2023-09-01 20:47:33,058] Trial 16 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:18, 29.62s/it]\n",
      "[I 2023-09-01 20:48:02,935] Trial 17 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:07, 29.24s/it]\n",
      "[I 2023-09-01 20:48:32,377] Trial 18 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:06, 29.18s/it]\n",
      "[I 2023-09-01 20:49:01,758] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:24, 29.81s/it]\n",
      "[I 2023-09-01 20:49:31,774] Trial 20 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:07, 29.23s/it]\n",
      "[I 2023-09-01 20:50:01,351] Trial 21 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:24, 29.82s/it]\n",
      "[I 2023-09-01 20:50:31,519] Trial 22 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:23, 29.79s/it]\n",
      "[I 2023-09-01 20:51:01,496] Trial 23 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:23, 29.77s/it]\n",
      "[I 2023-09-01 20:51:31,470] Trial 24 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:22, 29.75s/it]\n",
      "[I 2023-09-01 20:52:01,418] Trial 25 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:30<14:31, 30.06s/it]\n",
      "[I 2023-09-01 20:52:31,805] Trial 26 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:22, 29.73s/it]\n",
      "[I 2023-09-01 20:53:01,766] Trial 27 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:30<14:40, 30.35s/it]\n",
      "[I 2023-09-01 20:53:32,317] Trial 28 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:19, 29.65s/it]\n",
      "[I 2023-09-01 20:54:02,383] Trial 29 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:12, 29.38s/it]\n",
      "[I 2023-09-01 20:54:32,069] Trial 30 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:23, 29.77s/it]\n",
      "[I 2023-09-01 20:55:02,038] Trial 31 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:26, 29.88s/it]\n",
      "[I 2023-09-01 20:55:32,125] Trial 32 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:20, 29.69s/it]\n",
      "[I 2023-09-01 20:56:02,169] Trial 33 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:30<14:32, 30.10s/it]\n",
      "[I 2023-09-01 20:56:32,514] Trial 34 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:23, 29.78s/it]\n",
      "[I 2023-09-01 20:57:02,504] Trial 35 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:28, 29.96s/it]\n",
      "[I 2023-09-01 20:57:32,651] Trial 36 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:26, 29.88s/it]\n",
      "[I 2023-09-01 20:58:02,767] Trial 37 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:30<14:37, 30.26s/it]\n",
      "[I 2023-09-01 20:58:33,258] Trial 38 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:12, 29.40s/it]\n",
      "[I 2023-09-01 20:59:02,892] Trial 39 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:20, 29.67s/it]\n",
      "[I 2023-09-01 20:59:32,760] Trial 40 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:14, 29.48s/it]\n",
      "[I 2023-09-01 21:00:02,444] Trial 41 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:14, 29.45s/it]\n",
      "[I 2023-09-01 21:00:32,134] Trial 42 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:21, 29.70s/it]\n",
      "[I 2023-09-01 21:01:02,032] Trial 43 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:28, 29.95s/it]\n",
      "[I 2023-09-01 21:01:32,190] Trial 44 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:29, 29.97s/it]\n",
      "[I 2023-09-01 21:02:02,350] Trial 45 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:12, 29.38s/it]\n",
      "[I 2023-09-01 21:02:31,936] Trial 46 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:20, 29.68s/it]\n",
      "[I 2023-09-01 21:03:01,923] Trial 47 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:30<14:30, 30.02s/it]\n",
      "[I 2023-09-01 21:03:32,148] Trial 48 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:14, 29.47s/it]\n",
      "[I 2023-09-01 21:04:01,818] Trial 49 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:29, 30.00s/it]\n",
      "[I 2023-09-01 21:04:32,027] Trial 50 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:15, 29.51s/it]\n",
      "[I 2023-09-01 21:05:01,740] Trial 51 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:22, 29.76s/it]\n",
      "[I 2023-09-01 21:05:31,707] Trial 52 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:30<14:47, 30.60s/it]\n",
      "[I 2023-09-01 21:06:02,660] Trial 53 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:30<14:34, 30.16s/it]\n",
      "[I 2023-09-01 21:06:33,029] Trial 54 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:29, 29.98s/it]\n",
      "[I 2023-09-01 21:07:03,332] Trial 55 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:30<14:41, 30.39s/it]\n",
      "[I 2023-09-01 21:07:33,938] Trial 56 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:30<14:49, 30.68s/it]\n",
      "[I 2023-09-01 21:08:04,854] Trial 57 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:20, 29.69s/it]\n",
      "[I 2023-09-01 21:08:34,730] Trial 58 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:30<14:30, 30.01s/it]\n",
      "[I 2023-09-01 21:09:04,941] Trial 59 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:30<14:46, 30.58s/it]\n",
      "[I 2023-09-01 21:09:35,873] Trial 60 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:30<14:41, 30.39s/it]\n",
      "[I 2023-09-01 21:10:06,479] Trial 61 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:30<14:36, 30.22s/it]\n",
      "[I 2023-09-01 21:10:36,905] Trial 62 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:30<14:47, 30.59s/it]\n",
      "[I 2023-09-01 21:11:07,698] Trial 63 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:30<14:53, 30.83s/it]\n",
      "[I 2023-09-01 21:11:38,720] Trial 64 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:30<14:33, 30.11s/it]\n",
      "[I 2023-09-01 21:12:09,200] Trial 65 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:26, 29.88s/it]\n",
      "[I 2023-09-01 21:12:39,312] Trial 66 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:30<14:34, 30.16s/it]\n",
      "[I 2023-09-01 21:13:09,663] Trial 67 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:23, 29.79s/it]\n",
      "[I 2023-09-01 21:13:39,674] Trial 68 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:31<15:05, 31.21s/it]\n",
      "[I 2023-09-01 21:14:11,227] Trial 69 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:30<14:31, 30.06s/it]\n",
      "[I 2023-09-01 21:14:41,493] Trial 70 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:25, 29.84s/it]\n",
      "[I 2023-09-01 21:15:11,675] Trial 71 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:16, 29.54s/it]\n",
      "[I 2023-09-01 21:15:41,421] Trial 72 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:21, 29.72s/it]\n",
      "[I 2023-09-01 21:16:11,341] Trial 73 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:30<14:38, 30.29s/it]\n",
      "[I 2023-09-01 21:16:41,831] Trial 74 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:30<14:38, 30.30s/it]\n",
      "[I 2023-09-01 21:17:12,482] Trial 75 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:30<14:33, 30.13s/it]\n",
      "[I 2023-09-01 21:17:42,846] Trial 76 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:30<14:37, 30.26s/it]\n",
      "[I 2023-09-01 21:18:13,293] Trial 77 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:23, 29.76s/it]\n",
      "[I 2023-09-01 21:18:43,251] Trial 78 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:30<14:40, 30.35s/it]\n",
      "[I 2023-09-01 21:19:13,800] Trial 79 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:29, 29.97s/it]\n",
      "[I 2023-09-01 21:19:43,970] Trial 80 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:27, 29.92s/it]\n",
      "[I 2023-09-01 21:20:14,226] Trial 81 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:30<14:31, 30.06s/it]\n",
      "[I 2023-09-01 21:20:44,637] Trial 82 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:21, 29.72s/it]\n",
      "[I 2023-09-01 21:21:14,574] Trial 83 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:30<14:32, 30.08s/it]\n",
      "[I 2023-09-01 21:21:44,908] Trial 84 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:30<14:35, 30.18s/it]\n",
      "[I 2023-09-01 21:22:15,293] Trial 85 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:30<14:41, 30.39s/it]\n",
      "[I 2023-09-01 21:22:45,878] Trial 86 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:30<14:50, 30.72s/it]\n",
      "[I 2023-09-01 21:23:16,931] Trial 87 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:11, 29.36s/it]\n",
      "[I 2023-09-01 21:23:46,573] Trial 88 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:30<14:38, 30.28s/it]\n",
      "[I 2023-09-01 21:24:17,144] Trial 89 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:30<14:36, 30.22s/it]\n",
      "[I 2023-09-01 21:24:47,713] Trial 90 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:19, 29.62s/it]\n",
      "[I 2023-09-01 21:25:17,538] Trial 91 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:31<15:00, 31.04s/it]\n",
      "[I 2023-09-01 21:25:48,916] Trial 92 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:30<14:32, 30.08s/it]\n",
      "[I 2023-09-01 21:26:19,219] Trial 93 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:17, 29.58s/it]\n",
      "[I 2023-09-01 21:26:49,000] Trial 94 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:19, 29.65s/it]\n",
      "[I 2023-09-01 21:27:18,988] Trial 95 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:30<14:43, 30.45s/it]\n",
      "[I 2023-09-01 21:27:49,788] Trial 96 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:18, 29.59s/it]\n",
      "[I 2023-09-01 21:28:19,712] Trial 97 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:28, 29.95s/it]\n",
      "[I 2023-09-01 21:28:49,850] Trial 98 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:29<14:17, 29.57s/it]\n",
      "[I 2023-09-01 21:29:19,658] Trial 99 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No trials are completed yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(objective, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m trial \u001b[38;5;241m=\u001b[39m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_trial\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Value: \u001b[39m\u001b[38;5;124m\"\u001b[39m, trial\u001b[38;5;241m.\u001b[39mvalue)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Params: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/study/study.py:160\u001b[0m, in \u001b[0;36mStudy.best_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_multi_objective():\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA single best trial cannot be retrieved from a multi-objective study. Consider \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing Study.best_trials to retrieve a list containing the best trials.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    158\u001b[0m     )\n\u001b[0;32m--> 160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_storage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_study_id\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/optuna/storages/_in_memory.py:234\u001b[0m, in \u001b[0;36mInMemoryStorage.get_best_trial\u001b[0;34m(self, study_id)\u001b[0m\n\u001b[1;32m    231\u001b[0m best_trial_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_studies[study_id]\u001b[38;5;241m.\u001b[39mbest_trial_id\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_trial_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo trials are completed yet.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_studies[study_id]\u001b[38;5;241m.\u001b[39mdirections) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial can be obtained only for single-objective optimization.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    238\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: No trials are completed yet."
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "accuracy = Accuracy(task=\"multiclass\", num_classes=NUM_CLASSES, top_k=1).to(device)\n",
    "\n",
    "trial_num = -1\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    if key == \"num_features\":\n",
    "        print(\"    {}: {}\".format(key, 256+value*16))\n",
    "    else:\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
